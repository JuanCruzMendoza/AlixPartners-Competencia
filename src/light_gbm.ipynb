{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c829a1e6",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e91017e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from datetime import timedelta\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca5b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos el directorio para importar las funciones de func_aux\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(os.getcwd()).absolute().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea9c16ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.funcs_aux import features_rolling_mean_std, optimizacion_precios, crear_price_grid, walk_forward_forecast, features_rolling_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcf5bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_unidos = pd.read_csv(\"../data/procesados/datos_unidos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba4409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_unidos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb67579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_categoricas = ['SKU', 'STORE_ID', 'REGION',\n",
    "       'CITY', 'STATE', 'STORE_TYPE',  'CATEGORY', 'GROUP', 'SUBGROUP', 'GROUP_TYPE',\n",
    "       'PRICE_GROUP_ID', 'BRAND', \"DAY_OF_WEEK\"]\n",
    "\n",
    "target = \"TOTAL_SALES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffe975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols_categoricas:\n",
    "    datos_unidos[col] = datos_unidos[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda2426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_unidos.sort_values(by=[\"DATE\", \"STORE_ID\", \"SKU\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d6e6b0",
   "metadata": {},
   "source": [
    "## Feature aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377af809",
   "metadata": {},
   "source": [
    "Primero, haremos el promedio de ventas por SKU X STORE_ID de los últimos 7, 30 y 90 días, para compensar el hecho de que no es posible (por limitaciones computacionales) completar todo el dataset con los días en que no hubo transacciones de un producto.\n",
    "\n",
    "De esta manera, el modelo podrá dilucidar las épocas en donde no hay ventas de ciertos productos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb128e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_unidos = datos_unidos.sort_values(\"DATE\").reset_index(drop=True)\n",
    "# Guardamos el índice donde cambia la fecha para acceso rápido\n",
    "cambios_dia = datos_unidos[\"DATE\"].ne(datos_unidos[\"DATE\"].shift()).to_numpy().nonzero()[0]\n",
    "fechas_unicas = datos_unidos[\"DATE\"].unique()\n",
    "\n",
    "# Lista única de combinaciones SKU-STORE_ID\n",
    "combinaciones = datos_unidos[[\"SKU\", \"STORE_ID\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8060b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rellenar_faltantes(df, fecha):\n",
    "    # Todas las combinaciones para esta fecha\n",
    "    comb_fecha = combinaciones.copy()\n",
    "    comb_fecha[\"DATE\"] = fecha\n",
    "    # Merge para meter TOTAL_SALES=0 donde falta\n",
    "    df_completo = comb_fecha.merge(df, on=[\"SKU\", \"STORE_ID\", \"DATE\"], how=\"left\")\n",
    "    df_completo[\"TOTAL_SALES\"] = df_completo[\"TOTAL_SALES\"].fillna(0)\n",
    "    return df_completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c959a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = pd.DataFrame()\n",
    "resultados = []\n",
    "windows = [7, 30, 90]\n",
    "\n",
    "for window in windows:\n",
    "    datos_unidos[f\"SKU_STORE_mean_{window}D\"] = pd.NA\n",
    "\n",
    "    for fecha in fechas_unicas:\n",
    "        # Datos del día actual\n",
    "        df_dia = datos_unidos.loc[datos_unidos[\"DATE\"] == fecha, [\"SKU\", \"STORE_ID\", \"DATE\", \"TOTAL_SALES\"]]\n",
    "        df_dia_completo = rellenar_faltantes(df_dia, fecha)\n",
    "\n",
    "        # Agregar al buffer\n",
    "        buffer = pd.concat([buffer, df_dia_completo], ignore_index=True)\n",
    "\n",
    "        # Mantener sólo los últimos window+1 días (para limitar memoria)\n",
    "        if buffer[\"DATE\"].nunique() > window+1:\n",
    "            fecha_mas_vieja = buffer[\"DATE\"].min()\n",
    "            buffer = buffer[buffer[\"DATE\"] != fecha_mas_vieja]\n",
    "\n",
    "        # Filas originales del día actual\n",
    "        df_original_dia = datos_unidos.loc[datos_unidos[\"DATE\"] == fecha,\n",
    "                                        [\"SKU\", \"STORE_ID\", \"DATE\", \"TOTAL_SALES\"]]\n",
    "\n",
    "        # Calcular promedio con los días previos que haya \n",
    "        dias_previos = sorted(buffer[\"DATE\"].unique())[:-1]  # todos menos el actual\n",
    "        \n",
    "        if len(dias_previos) > 0:\n",
    "            # Tomar como máximo window días previos\n",
    "            dias_a_usar = dias_previos[-window:]\n",
    "            df_prev = buffer[buffer[\"DATE\"].isin(dias_a_usar)]\n",
    "            media_prev = df_prev.groupby([\"SKU\", \"STORE_ID\"], observed=False)[\"TOTAL_SALES\"].mean().reset_index()\n",
    "            media_prev[\"DATE\"] = fecha\n",
    "            media_prev.rename(columns={\"TOTAL_SALES\": f\"SKU_STORE_mean_{window}D\"}, inplace=True)\n",
    "\n",
    "            # Actualizar directamente en el dataset original\n",
    "            idx_update = datos_unidos.index[datos_unidos[\"DATE\"] == fecha]\n",
    "            merged = datos_unidos.loc[idx_update, [\"SKU\", \"STORE_ID\", \"DATE\"]].merge(\n",
    "                media_prev, on=[\"SKU\", \"STORE_ID\", \"DATE\"], how=\"left\")\n",
    "\n",
    "            # Si no se creó la columna en el merge, la creamos con NaN\n",
    "            if f\"SKU_STORE_mean_{window}D\" not in merged.columns:\n",
    "                merged[f\"SKU_STORE_mean_{window}D\"] = pd.NA\n",
    "\n",
    "            datos_unidos.loc[idx_update, f\"SKU_STORE_mean_{window}D\"] = merged[f\"SKU_STORE_mean_{window}D\"].values\n",
    "\n",
    "    datos_unidos.fillna({f\"SKU_STORE_mean_{window}D\":0}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e886c",
   "metadata": {},
   "source": [
    "Ahora, haremos el promedio y desviación estándar de las ventas por subgrupo y por categoría, de manera que el modelo pueda entender mejor los cambios de ventas por épocas del año de grupos más grandes de productos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca3fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_rolling_mean_std(datos_unidos, group=\"SUBGROUP\", windows=[30, 90, 180])\n",
    "features_rolling_mean_std(datos_unidos, group=\"SKU\", windows=[30, 90, 180])\n",
    "features_rolling_mean_std(datos_unidos, group=\"STORE_ID\", windows=[30, 90, 180])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8f1eba",
   "metadata": {},
   "source": [
    "## Test de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d237e544",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f524a3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7bfcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_lightgbm(df, features, target_col, date_col, categorical_cols,\n",
    "                          train_days=365, step_days=30, forecast_days=7,\n",
    "                          params=None):\n",
    "    \"\"\"\n",
    "    df: DataFrame con features + target\n",
    "    target_col: nombre de la columna objetivo (ej. 'TOTAL_SALES')\n",
    "    date_col: columna con la fecha\n",
    "    categorical_cols: lista de columnas categóricas (deben ser dtype 'category')\n",
    "    train_days, step_days, forecast_days: enteros en días\n",
    "    params: dict de parámetros LightGBM\n",
    "    \"\"\"\n",
    "\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df = df.sort_values(date_col)\n",
    "\n",
    "    results = []\n",
    "    min_date = df[date_col].min()\n",
    "    max_date = df[date_col].max()\n",
    "    start_train_end = min_date + timedelta(days=train_days)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    while start_train_end + timedelta(days=forecast_days) <= max_date:\n",
    "        count+=1\n",
    "\n",
    "        print(f\"Walk-forward: iteracion numero {count}\")\n",
    "\n",
    "        # Train y Test\n",
    "        train_data = df[df[date_col] < start_train_end]\n",
    "        test_data = df[(df[date_col] >= start_train_end) &\n",
    "                       (df[date_col] < start_train_end + timedelta(days=forecast_days))]\n",
    "\n",
    "        if len(test_data) == 0:\n",
    "            break\n",
    "\n",
    "        # Creamos un validation set para early stopping\n",
    "        valid_days_inner = 7\n",
    "        train_end_inner = train_data[\"DATE\"].max() - timedelta(days=valid_days_inner)\n",
    "\n",
    "        train_inner = train_data[train_data[\"DATE\"] <= train_end_inner]\n",
    "        valid_inner = train_data[train_data[\"DATE\"] > train_end_inner]\n",
    "\n",
    "        X_train_inner = train_inner[features]\n",
    "        y_train_inner = train_inner[target_col]\n",
    "        X_valid_inner = valid_inner[features]\n",
    "        y_valid_inner = valid_inner[target_col]\n",
    "\n",
    "        # Dataset LightGBM\n",
    "        lgb_train = lgb.Dataset(X_train_inner, label=y_train_inner, categorical_feature=categorical_cols)\n",
    "        lgb_valid = lgb.Dataset(X_valid_inner, label=y_valid_inner, categorical_feature=categorical_cols, reference=lgb_train)\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            lgb_train,\n",
    "            valid_sets=[lgb_train, lgb_valid],\n",
    "            valid_names=[\"train_inner\", \"valid_inner\"]\n",
    "        )\n",
    "\n",
    "        # Predicciones\n",
    "        y_test_pred = model.predict(test_data[features], num_iteration=model.best_iteration)\n",
    "        y_train_pred = model.predict(X_train_inner,num_iteration=model.best_iteration)\n",
    "        \n",
    "        # Métricas\n",
    "        r2_test = r2_score(test_data[target], y_test_pred)\n",
    "        r2_train = r2_score(y_train_inner, y_train_pred)\n",
    "\n",
    "\n",
    "        results.append({\n",
    "            \"train_end_date\": start_train_end,\n",
    "            \"r2_train\": r2_train,\n",
    "            \"r2_test\": r2_test\n",
    "        })\n",
    "\n",
    "        start_train_end += timedelta(days=step_days)\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2af0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(datos_unidos.columns)\n",
    "features = [col for col in cols if col not in [\"DATE\", \"TOTAL_SALES\",\n",
    "                                               'INITIAL_TICKET_PRICE', 'BASE_PRICE', \"COSTOS\", \n",
    "                                               \"OPENDATE\", \"CLOSEDATE\", \"QUANTITY\", \"STORE_SUBGROUP_DATE_ID\"] ]\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b771c231",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lgb = walk_forward_lightgbm(\n",
    "    df=datos_unidos,\n",
    "    features=features,\n",
    "    target_col=\"TOTAL_SALES\",\n",
    "    date_col=\"DATE\",\n",
    "    categorical_cols=cols_categoricas,\n",
    "    train_days=365,\n",
    "    step_days=30,\n",
    "    forecast_days=7,\n",
    "    params={\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"verbosity\": 2,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"num_leaves\": 500,\n",
    "        \"max_depth\": 20,\n",
    "        \"min_data_in_leaf\": 50,\n",
    "        \"feature_fraction\": 1,\n",
    "        \"bagging_fraction\": 1,\n",
    "        \"bagging_freq\": 0,\n",
    "        \"early_stopping_round\": 20,\n",
    "        \"num_boost_round\":1000\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a55baf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lgb.to_csv(\"resultados_test/resultados_lgb5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2a0b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lgb.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0c5f8b",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e075ff73",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30340f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3a460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(datos_unidos.columns)\n",
    "features = [col for col in cols if col not in [\"DATE\", \"TOTAL_SALES\",\n",
    "                                               'INITIAL_TICKET_PRICE', 'BASE_PRICE', \"COSTOS\", \n",
    "                                               \"OPENDATE\", \"CLOSEDATE\", \"QUANTITY\", \"STORE_SUBGROUP_DATE_ID\"] ]\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0a4513",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"verbosity\": 1,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"num_leaves\": 200,\n",
    "        \"max_depth\": 20,\n",
    "        \"feature_fraction\": 0.9,\n",
    "        \"bagging_fraction\": 0.9,\n",
    "        \"bagging_freq\": 1,\n",
    "\t\t\"num_boost_round\" : 100,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3d748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = lgb.Dataset(datos_unidos[features], datos_unidos[\"TOTAL_SALES\"], categorical_feature=cols_categoricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e5cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = lgb.train(params, data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87543e0e",
   "metadata": {},
   "source": [
    "### Template dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e13115",
   "metadata": {},
   "source": [
    "Primero, creamos un dataframe base con todos los productos y tiendas para los 7 días, de manera que el modelo pueda predecir las ventas de cada combinación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b5bf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_extraidas = ['SKU', 'STORE_ID', 'REGION',\n",
    "       'CITY', 'STATE', 'STORE_TYPE', 'CATEGORY', 'GROUP', 'SUBGROUP', 'GROUP_TYPE',\n",
    "       'PRICE_GROUP_ID', 'BRAND', 'YEAR_OPEN', 'YEAR_CLOSE', 'MONTH_OPEN', 'MONTH_CLOSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce2babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un dataframe con todas las combinaciones de SKU X STORE_ID\n",
    "template = datos_unidos[columnas_extraidas].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bedf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos los ultimos costos de los productos\n",
    "ultimos_costos = (\n",
    "    datos_unidos\n",
    "    .groupby([\"SKU\", \"STORE_ID\"], as_index=False)\n",
    "    .last()[[\"SKU\", \"STORE_ID\", \"COSTOS\"]]\n",
    ")\n",
    "\n",
    "template = template.merge(ultimos_costos, on=[\"SKU\", \"STORE_ID\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dd3c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitamos las tiendas que ya cerraron\n",
    "template = template[template[\"YEAR_CLOSE\"] > 2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a55adc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay 150 (numero de tiendas) . 854 (numero de sku) combinaciones\n",
    "len(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9450db51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cada uno de los 7 dias tendra todas las combinaciones\n",
    "fechas = pd.date_range(start=\"2024-01-01\", periods=7, freq=\"D\")\n",
    "df_fechas = pd.DataFrame({\"DATE\": fechas})\n",
    "\n",
    "template = (\n",
    "    df_fechas.assign(key=1)\n",
    "    .merge(template.assign(key=1), on=\"key\")\n",
    "    .drop(columns=\"key\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5251daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features agregados\n",
    "template[\"DATE\"] = pd.to_datetime(template[\"DATE\"])\n",
    "template[\"YEAR\"] = template[\"DATE\"].dt.year\n",
    "template[\"MONTH\"] = template[\"DATE\"].dt.month\n",
    "template[\"DAY\"] = template[\"DATE\"].dt.day\n",
    "template[\"DAY_OF_WEEK\"] = template[\"DATE\"].dt.day_name()\n",
    "template[\"WEEK\"] = template[\"DATE\"].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e6b542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasamos las columnas al type adecaudo\n",
    "for col in cols_categoricas:\n",
    "    template[col] = template[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dca1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como el modelo lo entrenaremos con 152 tiendas, pero dos de ellas cerraron y solo haremos la predicción de 150 tiendas, \n",
    "# necesitamos ajustar las categorias para que funcione correctamente lgb\n",
    "type_stores = pd.api.types.CategoricalDtype(categories=datos_unidos[\"STORE_ID\"].unique())\n",
    "template[\"STORE_ID\"] = template[\"STORE_ID\"].astype(type_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7143cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = template.sort_values(by=[\"DATE\", \"STORE_ID\", \"SKU\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42fab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = features_rolling_template(df=datos_unidos, template=template, group= \"SUBGROUP\", windows=[30, 90, 180])\n",
    "template = features_rolling_template(df=datos_unidos, template=template, group= \"SKU\", windows=[30, 90, 180])\n",
    "template = features_rolling_template(df=datos_unidos, template=template, group= \"STORE_ID\", windows=[30, 90, 180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46de75b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "template.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b0a0c8",
   "metadata": {},
   "source": [
    "### Optimizacion de precios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c7d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_grid = crear_price_grid(datos_unidos, n_prices=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e06fd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_y_pred, mejor_sales, mejor_gain, mejor_config = optimizacion_precios(template=template, model=model_lgb, price_grid=price_grid,\n",
    "                                                             features=features, n_iter=10, target=\"GAIN\", \n",
    "                                                             save_dir=\"resultados_optimizacion\",\n",
    "                                                             file_name=\"mejor_config_lgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b2d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_df = pd.read_csv(\"resultados_optimizacion/mejor_config_lgb.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
